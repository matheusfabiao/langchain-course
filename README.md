# ğŸ¤– Curso de LangChain para IA Generativa

[![Python Version](https://img.shields.io/badge/python-3.12%2B-blue.svg)](https://www.python.org/downloads/)
[![UV Package Manager](https://img.shields.io/badge/package%20manager-uv-blueviolet)](https://github.com/astral-sh/uv)
[![LangChain Version](https://img.shields.io/badge/langchain-0.3.23%2B-green)](https://python.langchain.com/)

Curso completo de LangChain para InteligÃªncia Artificial Generativa, oferecendo uma abordagem prÃ¡tica para criar aplicaÃ§Ãµes poderosas. Este curso estÃ¡ disponÃ­vel em duas versÃµes: uma utilizando OpenAI e outra com Ollama, permitindo que vocÃª escolha a opÃ§Ã£o mais adequada Ã s suas necessidades financeiras.

> ğŸ“ Adaptado do curso original do professor Brandon Hancock ([@aiwithbrandon](https://www.youtube.com/@aiwithbrandon)) para a nova versÃ£o do LangChain, incluindo uma implementaÃ§Ã£o alternativa com Ollama.

## ğŸ“‹ PrÃ©-requisitos

- Python 3.12 ou superior
- UV Package Manager
- Conta na OpenAI (para a versÃ£o OpenAI) ou Ollama instalado localmente (para a versÃ£o Ollama)

## ğŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/matheusfabiao/langchain-course.git
cd langchain-course
```

2. Configure o ambiente Python:
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/macOS
```

3. Instale as dependÃªncias com UV:
```bash
uv pip install -r requirements.txt
```

4. Configure as variÃ¡veis de ambiente:
```bash
cp .env.example .env
# Edite o arquivo .env com suas credenciais
```

## ğŸ—‚ï¸ Estrutura do Projeto

```
â”œâ”€â”€ OpenAI/                 # Exemplos usando OpenAI
â”‚   â”œâ”€â”€ 1_chat_model_basic.py
â”‚   â”œâ”€â”€ 2_chat_model_basic_conversation.py
â”‚   â””â”€â”€ 3_chat_model_alternatives.py
â”œâ”€â”€ Ollama/                 # Exemplos usando Ollama
â”‚   â””â”€â”€ 1_chat_models/
â”‚       â”œâ”€â”€ 1_chat_model_basic.py
â”‚       â”œâ”€â”€ 2_chat_model_basic_conversation.py
â”‚       â””â”€â”€ 3_chat_model_alternatives.py
â””â”€â”€ pyproject.toml         # ConfiguraÃ§Ãµes do projeto
```

## ğŸ’» Exemplos de Uso

### VersÃ£o OpenAI
```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

model = ChatOpenAI(model_name='gpt-4o')
result = model.invoke([
    SystemMessage(content='Solve the following math problems.'),
    HumanMessage(content='What is 81 divided by 9?')
])
```

### VersÃ£o Ollama
```python
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage

model = ChatOllama(model='qwen2.5:3b')
result = model.invoke([
    SystemMessage(content='Solve the following math problems.'),
    HumanMessage(content='What is 81 divided by 9?')
])
```

## ğŸ› ï¸ Ferramentas e DependÃªncias

- LangChain (â‰¥0.3.23)
- LangChain OpenAI (â‰¥0.3.12)
- LangChain Ollama (â‰¥0.3.1)
- LangChain Chroma (â‰¥0.2.2)
- LangChain HuggingFace (â‰¥0.1.2)
- Python-dotenv (â‰¥1.1.0)

### Ferramentas de Desenvolvimento

- Blue (â‰¥0.9.1) - Formatador de cÃ³digo
- ISort (â‰¥6.0.1) - Organizador de imports
- Taskipy (â‰¥1.14.1) - Executor de tarefas

## ğŸ“ Tarefas DisponÃ­veis

Utilize o Taskipy para executar tarefas comuns:

```bash
# Formatar o cÃ³digo (Blue + ISort)
task format

# Executar um arquivo especÃ­fico
task run 1_chat_models/1_chat_model_basic.py
```

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o do LangChain](https://python.langchain.com/)
- [Canal do Brandon Hancock](https://www.youtube.com/@aiwithbrandon)
- [DocumentaÃ§Ã£o do Ollama](https://ollama.ai/)

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para mais detalhes.

---

â­ Se este curso foi Ãºtil para vocÃª, considere dar uma estrela no repositÃ³rio!